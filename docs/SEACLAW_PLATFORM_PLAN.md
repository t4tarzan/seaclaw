# SeaClaw Platform Plan â€” Multi-Tenant Agent-as-a-Service

> **Date:** 2026-02-25
> **Status:** Draft â€” awaiting review
> **Goal:** Turn SeaClaw + SeaZero into a multi-tenant platform where each user gets an isolated AI agent accessible via Telegram, WebChat, or SSH TUI â€” with the security architecture that makes SeaClaw unique.

---

## 1. The Core Architecture (What We Already Have)

### The SeaZero Security Model

SeaClaw is NOT a simple LLM wrapper. It's a **two-tier architecture** where security and work happen in different places:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TIER 1: SeaClaw (C11 binary, 203 KB, 28 MB RAM)            â”‚
â”‚  "The Gatekeeper"                                            â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Grammar      â”‚  â”‚ PII         â”‚  â”‚ Local/Tiny LLM       â”‚â”‚
â”‚  â”‚ Shield       â”‚  â”‚ Firewall    â”‚  â”‚ (Ollama/qwen-tiny)   â”‚â”‚
â”‚  â”‚              â”‚  â”‚             â”‚  â”‚                       â”‚â”‚
â”‚  â”‚ â€¢ Input      â”‚  â”‚ â€¢ Email     â”‚  â”‚ â€¢ Decides routing     â”‚â”‚
â”‚  â”‚   injection  â”‚  â”‚ â€¢ Phone     â”‚  â”‚ â€¢ Simple tasks        â”‚â”‚
â”‚  â”‚   detection  â”‚  â”‚ â€¢ SSN       â”‚  â”‚ â€¢ Tool selection      â”‚â”‚
â”‚  â”‚ â€¢ Output     â”‚  â”‚ â€¢ Credit    â”‚  â”‚ â€¢ Redaction decisions  â”‚â”‚
â”‚  â”‚   injection  â”‚  â”‚   card      â”‚  â”‚ â€¢ Summarization       â”‚â”‚
â”‚  â”‚   detection  â”‚  â”‚ â€¢ IP addr   â”‚  â”‚                       â”‚â”‚
â”‚  â”‚ â€¢ Tool name  â”‚  â”‚             â”‚  â”‚ Runs on Raspberry Pi  â”‚â”‚
â”‚  â”‚   validation â”‚  â”‚ [REDACTED]  â”‚  â”‚ or 4 GB RAM server    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                              â”‚
â”‚  58 built-in tools â”‚ SQLite DB â”‚ Arena allocator â”‚ Audit log â”‚
â”‚  Telegram bot â”‚ TUI â”‚ Bus â”‚ Channels â”‚ Sessions â”‚ Recall DB  â”‚
â”‚                                                              â”‚
â”‚  Proxy server on port 7432:                                  â”‚
â”‚  â€¢ Validates internal token from Agent Zero                  â”‚
â”‚  â€¢ Checks daily token budget (100K tokens/day)               â”‚
â”‚  â€¢ Swaps fake token â†’ real API key                           â”‚
â”‚  â€¢ Forwards to real LLM endpoint                             â”‚
â”‚  â€¢ Logs all usage to SQLite                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP (localhost only)
                             â”‚ Token: internal bridge token
                             â”‚ Port: 8080 (Agent Zero)
                             â”‚ Port: 7432 (Proxy)
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TIER 2: Agent Zero (Python, Kali Linux Docker, 2 GB RAM)    â”‚
â”‚  "The Worker"                                                â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Python       â”‚  â”‚ Cloud LLM    â”‚  â”‚ Kali Linux tools     â”‚â”‚
â”‚  â”‚ Runtime      â”‚  â”‚ (via proxy)  â”‚  â”‚                       â”‚â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚ â€¢ nmap, nikto         â”‚â”‚
â”‚  â”‚ â€¢ pip installâ”‚  â”‚ â€¢ GPT-4o     â”‚  â”‚ â€¢ sqlmap, dirb        â”‚â”‚
â”‚  â”‚ â€¢ Any libraryâ”‚  â”‚ â€¢ Claude 3   â”‚  â”‚ â€¢ hydra, john         â”‚â”‚
â”‚  â”‚ â€¢ Web scrape â”‚  â”‚ â€¢ Qwen 72B   â”‚  â”‚ â€¢ Network scanning    â”‚â”‚
â”‚  â”‚ â€¢ Code exec  â”‚  â”‚ (local)      â”‚  â”‚ â€¢ Vuln assessment     â”‚â”‚
â”‚  â”‚ â€¢ File I/O   â”‚  â”‚              â”‚  â”‚ â€¢ Pen testing         â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                              â”‚
â”‚  LOCKED DOWN:                                                â”‚
â”‚  â€¢ read_only rootfs â”‚ cap_drop: ALL â”‚ no-new-privileges     â”‚
â”‚  â€¢ seccomp profile â”‚ 1 CPU â”‚ 2 GB RAM â”‚ 100 PIDs max        â”‚
â”‚  â€¢ tmpfs only for /tmp and /run                              â”‚
â”‚  â€¢ Never sees real API key (gets fake internal token)        â”‚
â”‚  â€¢ All LLM calls routed through SeaClaw proxy (port 7432)   â”‚
â”‚  â€¢ Shared workspace volume for file exchange                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Happens When a User Sends a Message

```
User: "Scan my network for vulnerabilities"
  â”‚
  â–¼
TIER 1 â€” SeaClaw (C binary):
  â”œâ”€â”€ 1. Grammar Shield: scan input for injection attacks
  â”œâ”€â”€ 2. PII Firewall: redact any PII in the prompt BEFORE sending to LLM
  â”œâ”€â”€ 3. Load history from SQLite (last 20 messages)
  â”œâ”€â”€ 4. Send to local/tiny LLM (or cloud LLM via configured provider)
  â”‚      LLM sees tool #58: "agent_zero â€” delegate complex tasks"
  â”‚      LLM decides: this needs Agent Zero (network scanning = complex)
  â”‚      LLM responds: {"tool": "agent_zero", "params": {"task": "scan network..."}}
  â”‚
  â”œâ”€â”€ 5. SeaClaw executes tool #58 â†’ sea_zero_delegate()
  â”‚      POST http://localhost:8080/api/v1/task
  â”‚      {"task": "scan network...", "max_steps": 10, "timeout": 120}
  â”‚
  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚      â”‚ TIER 2 â€” Agent Zero (Python/Kali Docker):            â”‚
  â”‚      â”‚                                                      â”‚
  â”‚      â”‚  Step 1: Plan (calls "OpenAI" = actually proxy)      â”‚
  â”‚      â”‚    â†’ Proxy validates token, checks budget, swaps key â”‚
  â”‚      â”‚    â†’ Forwards to real LLM (cloud or local)           â”‚
  â”‚      â”‚    â†’ LLM returns plan                                â”‚
  â”‚      â”‚                                                      â”‚
  â”‚      â”‚  Step 2: Execute (pip install python-nmap, scan)     â”‚
  â”‚      â”‚  Step 3: Analyze results (another LLM call â†’ proxy)  â”‚
  â”‚      â”‚  Step 4: Generate report                             â”‚
  â”‚      â”‚  Step 5: Save to /agent/shared/report.html           â”‚
  â”‚      â”‚                                                      â”‚
  â”‚      â”‚  Return: {"result": "Found 15 hosts, 47 ports..."}  â”‚
  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”œâ”€â”€ 6. SeaClaw receives Agent Zero's result
  â”œâ”€â”€ 7. Output size limit check (64 KB max)
  â”œâ”€â”€ 8. Grammar Shield: scan OUTPUT for injection attacks
  â”œâ”€â”€ 9. PII Firewall: redact any PII in the OUTPUT
  â”œâ”€â”€ 10. Save both user message + response to SQLite
  â””â”€â”€ 11. Send clean response to user via Telegram/TUI
```

### The Security Guarantee

Every piece of data passes through SeaClaw's C-level filters **twice**:
- **Inbound**: Shield â†’ PII redact â†’ LLM
- **Outbound from LLM**: Shield â†’ PII redact â†’ User
- **Outbound from Agent Zero**: Size limit â†’ Shield â†’ PII redact â†’ User

This is what OpenClaw K8s Platform does NOT have. It sends raw prompts to raw LLM endpoints with zero filtering.

---

## 2. What OpenClaw K8s Does That We Need to Match

| OpenClaw K8s Feature | SeaClaw Status | Plan |
|---------------------|----------------|------|
| **Web signup form** (API keys, soul type) | âŒ | Phase C: Gateway UI |
| **Multi-user instances** | âŒ Single user | Phase B: Instance Manager |
| **Agent personalities (5 Souls)** | âœ… SOUL.md + USER.md | Already done, per-instance |
| **Real-time dashboard** (Kanban, chat) | âŒ | Phase C: Simple status dashboard |
| **PostgreSQL + pgvector** | âœ… SQLite + keyword recall | SQLite is lighter and sufficient |
| **Redis pub/sub** | âœ… sea_bus.c (compiled in) | Already better (zero dependencies) |
| **JWT auth** | âŒ | Phase C: Gateway auth |
| **Git integration** | âŒ | Future (Phase F) |
| **Prometheus + Grafana monitoring** | âŒ | sea_usage.c covers this lighter |
| **10 Docker containers** | 1 binary + 1 Docker container | SeaZero is already more efficient |

### What We Do BETTER Already

| Metric | OpenClaw K8s | SeaClaw + SeaZero |
|--------|-------------|-------------------|
| Per-instance RAM | 4+ GB (10 containers) | ~30 MB (SeaClaw) + 2 GB (Agent Zero shared) |
| Per-instance disk | ~2 GB Docker images | ~5 MB (binary + DB + config) |
| Startup time | 30-60 seconds | <50 milliseconds |
| Input security | None | Grammar Shield (byte-level, <1Î¼s) |
| Output security | None | Grammar Shield + PII Firewall |
| LLM key protection | JWT (user holds key) | Proxy (user never touches cloud key) |
| Memory system | pgvector (needs OpenAI API) | SQLite recall (no external API) |
| Audit trail | Gateway text logs | SQLite event log (queryable) |
| Code execution sandbox | None built-in | Kali Docker (cap_drop ALL, seccomp) |

---

## 3. Multi-Tenant Architecture

### The Key Decision: How Many Agent Zero Containers?

There are two models:

#### Model A: One Agent Zero Per User (Expensive, Maximum Isolation)
```
User Alice â†’ SeaClaw instance (28 MB) + Agent Zero container (2 GB) = ~2 GB total
User Bob   â†’ SeaClaw instance (28 MB) + Agent Zero container (2 GB) = ~2 GB total
                                                        8 GB VPS = 3-4 users max
```

#### Model B: Shared Agent Zero, Per-User SeaClaw (Efficient, Recommended)
```
User Alice â†’ SeaClaw instance (28 MB) â”€â”
User Bob   â†’ SeaClaw instance (28 MB) â”€â”€â”¤â”€â”€ Shared Agent Zero (2 GB)
User Carol â†’ SeaClaw instance (28 MB) â”€â”€â”¤   (task queue, one at a time)
User Dave  â†’ SeaClaw instance (28 MB) â”€â”˜
                                  Total: ~2.1 GB for 4 users
                                  8 GB VPS = 50-100 users (most won't use Agent Zero)
```

#### Model C: Hybrid â€” Shared Agent Zero + On-Demand Spawn (Best)
```
Default:  All users share one Agent Zero instance (2 GB)
          Tasks are queued, executed one at a time
          Good for: occasional complex tasks

Premium:  User gets a dedicated Agent Zero container
          Spawned on demand, killed after idle timeout (15 min)
          Good for: heavy pentest/automation workloads

Crew:     User brings their own device (Raspberry Pi, laptop)
          SeaClaw runs locally, Agent Zero runs on hub VPS
          Mesh connection via Tailscale
```

**Recommendation: Model C** â€” start with shared Agent Zero, add dedicated containers later.

---

## 4. Per-User Instance Layout

```
/var/seaclaw/
â”œâ”€â”€ master.db                       # Master database (all instances, users, billing)
â”œâ”€â”€ sea_claw                        # Single binary (shared by all instances)
â”œâ”€â”€ souls/                          # Soul templates
â”‚   â”œâ”€â”€ eva.md                      # The Analyst (temperature 0.3)
â”‚   â”œâ”€â”€ alex.md                     # The Developer (temperature 0.2)
â”‚   â”œâ”€â”€ tom.md                      # The Creative (temperature 0.9)
â”‚   â”œâ”€â”€ sarah.md                    # The Communicator
â”‚   â””â”€â”€ max.md                      # The Generalist
â”‚
â”œâ”€â”€ instances/
â”‚   â”œâ”€â”€ alice/                      # Alice's isolated instance
â”‚   â”‚   â”œâ”€â”€ config.json             # Her LLM config (provider, model, API URL)
â”‚   â”‚   â”œâ”€â”€ .env                    # Her API keys (encrypted at rest)
â”‚   â”‚   â”œâ”€â”€ seaclaw.db              # Her SQLite DB (chat history, recall, tasks)
â”‚   â”‚   â”œâ”€â”€ SOUL.md                 # Her chosen personality
â”‚   â”‚   â”œâ”€â”€ USER.md                 # Her user profile
â”‚   â”‚   â”œâ”€â”€ MEMORY.md               # Her agent's memory
â”‚   â”‚   â”œâ”€â”€ skills/                 # Her installed skills
â”‚   â”‚   â””â”€â”€ workspace/              # Shared volume with Agent Zero
â”‚   â”‚
â”‚   â”œâ”€â”€ bob/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â”œâ”€â”€ seaclaw.db
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ carol/
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ seazero/
    â”œâ”€â”€ docker-compose.yml          # Shared Agent Zero container
    â”œâ”€â”€ agent-zero.env              # Internal bridge token
    â””â”€â”€ proxy.conf                  # Proxy config (port 7432)
```

### Per-Instance Process

Each user gets their own `sea_claw` process:

```bash
# Alice's instance
sea_claw \
  --config /var/seaclaw/instances/alice/config.json \
  --db /var/seaclaw/instances/alice/seaclaw.db \
  --telegram <alice_bot_token> \
  --chat <alice_chat_id> \
  --gateway-port 31042 \
  --proxy-port 7432 \
  --workspace /var/seaclaw/instances/alice/workspace
```

- PID: 4521
- RAM: 28 MB
- Port: 31042 (WebChat + API)
- Telegram: polling her bot
- DB: her own SQLite file
- Proxy: shared port 7432 (routes to Agent Zero)

### LLM Key Handling â€” Three Scenarios

```
Scenario 1: User brings their own API key (BYOK)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ SeaClaw   â”‚â”€â”€â”€â”€â–¶â”‚ User's LLM   â”‚     â”‚ Agent Zero   â”‚
  â”‚ (Alice)   â”‚     â”‚ (OpenRouter)  â”‚     â”‚ (shared)     â”‚
  â”‚           â”‚     â”‚ sk-or-v1-... â”‚     â”‚              â”‚
  â”‚ Her key   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ Uses proxy   â”‚
  â”‚ in her    â”‚                          â”‚ â†’ same key   â”‚
  â”‚ config    â”‚     SeaClaw uses her     â”‚   swapped in â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     key directly          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Scenario 2: User uses platform's shared LLM (metered)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ SeaClaw   â”‚â”€â”€â”€â”€â–¶â”‚ Platform LLM â”‚     â”‚ Agent Zero   â”‚
  â”‚ (Bob)     â”‚     â”‚ (our key)    â”‚     â”‚ (shared)     â”‚
  â”‚           â”‚     â”‚              â”‚     â”‚              â”‚
  â”‚ No key    â”‚     â”‚ Proxy tracks â”‚     â”‚ Uses proxy   â”‚
  â”‚ needed    â”‚     â”‚ Bob's usage  â”‚     â”‚ â†’ our key    â”‚
  â”‚ from Bob  â”‚     â”‚ for billing  â”‚     â”‚   budget-    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   limited    â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Scenario 3: User runs local LLM (Ollama on their machine)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ SeaClaw   â”‚â”€â”€â”€â”€â–¶â”‚ Ollama       â”‚     â”‚ Agent Zero   â”‚
  â”‚ (Carol)   â”‚     â”‚ (localhost)  â”‚     â”‚ (shared)     â”‚
  â”‚           â”‚     â”‚ qwen:72b     â”‚     â”‚              â”‚
  â”‚ Crew node â”‚     â”‚              â”‚     â”‚ Uses proxy   â”‚
  â”‚ on RPi    â”‚     â”‚ On her Mac   â”‚     â”‚ â†’ routes to  â”‚
  â”‚           â”‚     â”‚ via Tailscaleâ”‚     â”‚   Ollama     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  (Mesh VPN)       (Captain hub)        (On captain)
```

---

## 5. Access Methods

### 5a. Telegram Bot (Already Works)

Each user creates their own Telegram bot via @BotFather, enters the token in the signup form. Their SeaClaw instance polls that bot. Zero infrastructure needed.

### 5b. WebChat (New â€” Phase A2)

Each instance exposes a WebSocket endpoint on its random port:
```
https://agents.seaclawagent.com/alice/chat
     â”‚
     â–¼ Nginx reverse proxy
     â”‚
     http://localhost:31042/chat  (Alice's SeaClaw instance)
```

Simple HTML/JS chat widget. No React, no Node.js â€” served as static HTML from SeaClaw's built-in HTTP server (`channel_webchat.c`).

### 5c. SSH TUI (New â€” Phase D2)

For power users who want the full terminal experience:
```
ssh -p 31043 alice@agents.seaclawagent.com
     â”‚
     â–¼ Nginx stream proxy or direct port
     â”‚
     SeaClaw TUI on Alice's instance
```

Or via Tailscale:
```
ssh alice@vps-hostname.ts.net -p 31043
```

### 5d. Mesh / Tailscale (New â€” Phase D1)

For users who run SeaClaw on their own hardware (Raspberry Pi, laptop) and want to connect to the hub:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User's Raspberry Pi      â”‚         â”‚ VPS Hub                  â”‚
â”‚                          â”‚         â”‚                          â”‚
â”‚ SeaClaw (crew mode)      â”‚â—„â”€â”€â”€â”€â”€â”€â–¶â”‚ SeaClaw (captain mode)   â”‚
â”‚ 203 KB, 28 MB RAM        â”‚  Mesh  â”‚ Agent Zero (Docker)      â”‚
â”‚ Telegram bot             â”‚  VPN   â”‚ Ollama (local LLM)       â”‚
â”‚                          â”‚ (9100/ â”‚ Proxy (7432)             â”‚
â”‚ Tailscale: 100.x.y.z    â”‚  9101) â”‚ Tailscale: 100.a.b.c    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User talks to Telegram bot on their Pi.
Pi's SeaClaw handles simple tasks locally (tools, file ops).
Complex tasks â†’ mesh â†’ hub â†’ Agent Zero â†’ cloud LLM â†’ back.
```

---

## 6. The Gateway Signup Form

### What It Collects

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¦€ Create Your Sea-Claw Agent                              â”‚
â”‚                                                              â”‚
â”‚  â”€â”€ Account â”€â”€                                               â”‚
â”‚  Username:        [_______________]                           â”‚
â”‚  Email:           [_______________]                           â”‚
â”‚                                                              â”‚
â”‚  â”€â”€ LLM Provider â”€â”€                                          â”‚
â”‚  â—‹ Bring your own key (BYOK)                                 â”‚
â”‚    Provider: [OpenRouter â–¼]                                   â”‚
â”‚    API Key:  [sk-or-v1-___________]  (encrypted, never logged)â”‚
â”‚    Model:    [qwen/qwen-2.5-72b â–¼]                           â”‚
â”‚  â—‹ Use platform LLM (metered, $0.001/1K tokens)              â”‚
â”‚  â—‹ Connect my local LLM (Ollama via Tailscale)               â”‚
â”‚    Ollama URL: [http://100.x.y.z:11434]                      â”‚
â”‚                                                              â”‚
â”‚  â”€â”€ Agent Personality â”€â”€                                      â”‚
â”‚  â—‹ Eva â€” The Analyst (precise, data-driven)                  â”‚
â”‚  â—‹ Alex â€” The Developer (technical, code-focused)            â”‚
â”‚  â— Tom â€” The Creative (expressive, brainstorming)            â”‚
â”‚  â—‹ Sarah â€” The Communicator (clear, teaching-oriented)       â”‚
â”‚  â—‹ Max â€” The Generalist (balanced, multi-tasking)            â”‚
â”‚  â—‹ Custom (paste your SOUL.md)                               â”‚
â”‚                                                              â”‚
â”‚  â”€â”€ Access Methods â”€â”€ (select one or more)                   â”‚
â”‚  â˜‘ Telegram Bot                                              â”‚
â”‚    Bot Token: [123456:ABC-DEF___________]                    â”‚
â”‚    Chat ID:   [________] (leave empty for any chat)          â”‚
â”‚  â˜‘ WebChat (browser)                                         â”‚
â”‚  â˜ SSH Terminal (advanced)                                   â”‚
â”‚    SSH Public Key: [ssh-rsa AAAA___________]                 â”‚
â”‚                                                              â”‚
â”‚  â”€â”€ Security â”€â”€                                              â”‚
â”‚  â˜‘ Enable PII Firewall (redact emails, phones, SSNs, etc.)  â”‚
â”‚  â˜‘ Enable Grammar Shield (injection detection)               â”‚
â”‚  â˜‘ Enable Agent Zero (complex task delegation)               â”‚
â”‚  Token budget: [100000] tokens/day                           â”‚
â”‚                                                              â”‚
â”‚  â”€â”€ Network Access â”€â”€                                        â”‚
â”‚  â—‹ Tailscale tunnel (zero open ports, recommended)           â”‚
â”‚  â—‹ Direct port (firewall-protected)                          â”‚
â”‚  â—‹ Mesh VPN (connect your own devices)                       â”‚
â”‚    Tailscale auth key: [tskey-___________]                   â”‚
â”‚                                                              â”‚
â”‚           [ ğŸ¦€ Create My Agent ]                             â”‚
â”‚                                                              â”‚
â”‚  Your agent will be ready in <2 seconds.                     â”‚
â”‚  203 KB binary. 28 MB RAM. 58 tools. Yours.                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Happens on Submit

```
POST /api/v1/agents/create
{
  "username": "alice",
  "email": "alice@example.com",
  "llm": {
    "mode": "byok",
    "provider": "openrouter",
    "api_key": "sk-or-v1-...",      // encrypted before storage
    "model": "qwen/qwen-2.5-72b"
  },
  "soul": "tom",
  "channels": {
    "telegram": {
      "enabled": true,
      "bot_token": "123456:ABC-DEF...",
      "chat_id": null
    },
    "webchat": { "enabled": true },
    "ssh": { "enabled": false }
  },
  "security": {
    "pii_firewall": true,
    "grammar_shield": true,
    "agent_zero": true,
    "token_budget": 100000
  },
  "network": {
    "mode": "tailscale"
  }
}
```

**Backend flow** (Instance Manager):

```
1. Validate all inputs
2. Encrypt API key with platform master key
3. mkdir /var/seaclaw/instances/alice/
4. Write config.json (provider, model, API URL â€” key stored encrypted)
5. Write .env (decrypted key, only readable by alice's process)
6. Copy souls/tom.md â†’ instances/alice/SOUL.md
7. Create empty seaclaw.db (schema auto-created on first run)
8. Pick random port: 31042 (WebChat) + 31043 (SSH, if enabled)
9. Fork sea_claw process with alice's config
10. If Tailscale: create serve rule â†’ alice gets https://vps.ts.net/alice/
11. Register in master.db: (alice, 31042, PID, tom, running, now())
12. Return access URLs to user
```

**Time: <2 seconds** (fork + exec is instant, SeaClaw starts in <50ms)

---

## 7. Build Phases

### Phase A: Feature Parity (Close OpenClaw Gaps)

**Must be done before going multi-tenant.**

| # | Task | Effort | Files | Status |
|---|------|--------|-------|--------|
| A1 | **SSE Streaming** â€” token-by-token response in TUI and Telegram | Medium | `sea_http.c`, `sea_agent.c` | âœ… Done (stream_cb exists) |
| A2 | **WebChat channel** â€” HTTP/WebSocket endpoint serving chat UI | Medium | `channel_webchat.c` (new) | âŒ |
| A3 | **Session compaction** â€” `/compact` summarizes history, keeps last 10 | Low | `sea_agent.c`, `sea_db.c` | Partial (auto-summarize exists) |
| A4 | **Skills directory** â€” load SKILL.md files from workspace | Low | `sea_skill.c` (existing) | âœ… Done |
| A5 | **WhatsApp channel** â€” via WhatsApp Business Cloud API | Medium | `channel_whatsapp.c` (new) | âŒ Future |

**Note on A1**: SSE streaming is already implemented â€” `sea_agent.c` has `stream_cb`, `sea_http_post_stream()`, and SSE parsing. The code at line 685-697 injects `"stream":true` and uses `sse_data_cb`. This was a gap that's already closed.

### Phase B: Instance Manager

| # | Task | Effort | New Files |
|---|------|--------|-----------|
| B1 | `sea_spawn.h/c` â€” fork/exec SeaClaw instances | Medium | `src/platform/sea_spawn.h/c` |
| B2 | Master DB schema â€” `instances`, `users`, `billing` tables | Low | `src/platform/sea_platform_db.c` |
| B3 | Port allocator â€” random ports 30000-32767, collision avoidance | Low | Part of `sea_spawn.c` |
| B4 | Health checker â€” periodic PID check, port ping, auto-restart | Low | Part of `sea_spawn.c` |
| B5 | Instance lifecycle â€” create, stop, restart, destroy, list | Medium | Part of `sea_spawn.c` |
| B6 | Config writer â€” generate per-instance config.json + .env + SOUL.md | Low | Part of `sea_spawn.c` |
| B7 | API key encryption â€” encrypt at rest, decrypt only for process .env | Medium | `sea_crypto.c` (new or existing) |
| B8 | SeaZero sharing â€” route multiple instances through shared proxy | Medium | `sea_proxy.c` modifications |

**B8 is critical**: Currently the proxy validates ONE internal token. For multi-tenant, the proxy needs to:
- Accept per-user tokens (each instance gets its own bridge token)
- Track token budget per user, not globally
- Route to the correct LLM endpoint (BYOK users have different providers)

```c
// Modified proxy flow for multi-tenant:
static void handle_chat_completions(int fd, ProxyRequest* req) {
    // 1. Extract token from Authorization header
    const char* token = req->auth_token;

    // 2. Look up which user this token belongs to
    UserConfig* user = lookup_user_by_token(token);
    if (!user) {
        send_json_error(fd, 401, "Invalid token");
        return;
    }

    // 3. Check THIS USER's budget
    if (!check_user_budget(user)) {
        send_json_error(fd, 429, "Daily token budget exceeded");
        return;
    }

    // 4. Use THIS USER's real API key
    snprintf(auth_hdr, sizeof(auth_hdr), "Authorization: Bearer %s",
             user->real_api_key);

    // 5. Forward to THIS USER's LLM endpoint
    sea_http_post_json_auth(user->real_api_url, body, auth_hdr, &arena, &resp);

    // 6. Log usage for THIS USER
    sea_db_sz_llm_log(db, user->username, user->provider, user->model,
                       tokens_in, tokens_out, cost, latency_ms, "ok", NULL);
}
```

### Phase C: Gateway UI

| # | Task | Effort | New Files |
|---|------|--------|-----------|
| C1 | Static HTML signup form (no React, no Node.js) | Low | `gateway/index.html` |
| C2 | `POST /api/v1/agents/create` endpoint in SeaClaw | Medium | `src/platform/sea_gateway.c` |
| C3 | `GET /api/v1/agents/list` â€” user's instances | Low | Part of gateway |
| C4 | `POST /api/v1/agents/{id}/stop` â€” stop instance | Low | Part of gateway |
| C5 | `GET /api/v1/agents/{id}/status` â€” instance health | Low | Part of gateway |
| C6 | `GET /api/v1/agents/{id}/usage` â€” token usage | Low | Part of gateway |
| C7 | Simple dashboard page (status, usage, controls) | Low | `gateway/dashboard.html` |
| C8 | JWT or session auth for gateway | Medium | Part of gateway |
| C9 | Nginx config for routing (gateway + per-instance WebChat) | Low | `nginx/seaclaw-platform.conf` |

**Architecture decision**: The gateway runs as a special "platform mode" of SeaClaw itself:
```bash
sea_claw --platform \
  --gateway-port 443 \
  --master-db /var/seaclaw/master.db \
  --instances-dir /var/seaclaw/instances/
```

This means NO new runtime dependencies. The gateway is just another mode of the same 203 KB binary.

### Phase D: Secure Access

| # | Task | Effort | Details |
|---|------|--------|---------|
| D1 | **Tailscale integration** â€” auto-create serve rules per instance | Low | Shell exec: `tailscale serve ...` |
| D2 | **SSH access** â€” per-instance SSH port via Nginx stream proxy | Medium | `nginx stream {}` block |
| D3 | **Mesh VPN** â€” allow crew nodes to connect via Tailscale | Low | Already works (mesh architecture) |
| D4 | **Cloudflare Tunnel** alternative (for users without Tailscale) | Low | `cloudflared tunnel ...` |

### Phase E: Agent Zero Multi-Tenant

| # | Task | Effort | Details |
|---|------|--------|---------|
| E1 | **Task queue** â€” multiple users share one Agent Zero, tasks queued | Medium | Queue in master.db, FIFO |
| E2 | **Per-user workspace isolation** â€” each user's tasks write to their workspace | Low | Mount `/var/seaclaw/instances/<user>/workspace` per task |
| E3 | **On-demand container spawn** â€” premium users get dedicated Agent Zero | High | Docker API from C (`sea_docker.c`) |
| E4 | **Idle timeout** â€” kill dedicated containers after 15 min idle | Low | Timer + `docker stop` |

### Phase F: Future

| # | Task | Notes |
|---|------|-------|
| F1 | Billing / metering (Stripe) | For platform LLM usage |
| F2 | Git integration | Like OpenClaw K8s |
| F3 | Custom Docker images | User uploads their own Agent Zero variant |
| F4 | Multi-region | Deploy SeaClaw instances across Hetzner DCs |
| F5 | Federation | Multiple VPS hubs connected via mesh |

---

## 8. Comparison: Final Architecture vs. OpenClaw K8s

| Aspect | OpenClaw K8s Platform | SeaClaw Platform |
|--------|----------------------|-----------------|
| **Per-user footprint** | 4+ GB (10 containers) | 28 MB (1 process) |
| **Users on 8 GB VPS** | 1 | 50-200 |
| **Startup time** | 30-60 seconds | <2 seconds |
| **Dependencies** | Docker, PostgreSQL, Redis, Node.js, Python | 1 binary + 1 Docker container |
| **Input/output security** | âŒ None | âœ… Grammar Shield + PII Firewall |
| **LLM key protection** | JWT (user holds key in browser) | Proxy (key never leaves server) |
| **Code execution** | âŒ No sandbox | âœ… Kali Docker (seccomp, cap_drop) |
| **Memory system** | pgvector (needs OpenAI) | SQLite recall (zero external deps) |
| **Multi-channel** | Web UI only | Telegram + WebChat + SSH + Mesh |
| **Monitoring** | Prometheus + Grafana (300 MB) | Built-in sea_usage.c (0 MB) |
| **Secure tunnels** | âŒ None | âœ… Tailscale mesh VPN |
| **Edge deployment** | âŒ Needs 4+ GB | âœ… Runs on Raspberry Pi |

### The Pitch

> **"200 AI agents on one $10/month VPS."**
>
> Each agent: 203 KB binary, 28 MB RAM, 58 built-in tools, Grammar Shield,
> PII Firewall, Agent Zero delegation, Telegram + WebChat + SSH access.
>
> OpenClaw K8s needs 10 Docker containers and 4 GB RAM for ONE user.
> SeaClaw does it with one process and 28 MB.

---

## 9. Build Order Summary

```
Phase A: Close feature gaps           â† 1-2 weeks
  â””â”€â”€ A2: WebChat channel (main missing piece)

Phase B: Instance manager             â† 2-3 weeks
  â”œâ”€â”€ B1-B6: fork/exec, master DB, port alloc, health check
  â”œâ”€â”€ B7: API key encryption
  â””â”€â”€ B8: Multi-tenant proxy (per-user tokens + budgets)

Phase C: Gateway UI                   â† 1-2 weeks
  â”œâ”€â”€ C1-C2: Signup form + create API
  â”œâ”€â”€ C3-C7: Dashboard + management APIs
  â””â”€â”€ C8-C9: Auth + Nginx config

Phase D: Secure access                â† 1 week
  â”œâ”€â”€ D1: Tailscale auto-setup
  â”œâ”€â”€ D2: SSH access
  â””â”€â”€ D3-D4: Mesh + Cloudflare alternatives

Phase E: Agent Zero multi-tenant      â† 2-3 weeks
  â”œâ”€â”€ E1-E2: Task queue + workspace isolation
  â””â”€â”€ E3-E4: On-demand containers + idle timeout

Phase F: Future                       â† Ongoing
  â””â”€â”€ Billing, Git, custom images, multi-region
```

**Total estimated: 7-11 weeks to MVP (Phases A-D)**
**Full platform with dedicated Agent Zero: 9-14 weeks (A-E)**

---

## 10. What NOT to Build

Lessons from the OpenClaw comparison doc:

- **âŒ Native macOS/iOS/Android apps** â€” wrong stack. Telegram + WebChat covers 95%.
- **âŒ React dashboard with Kanban** â€” overkill. Simple HTML status page is enough.
- **âŒ PostgreSQL + Redis** â€” SQLite per-instance is lighter, faster, zero-dependency.
- **âŒ Kubernetes (yet)** â€” Docker Compose for Agent Zero is sufficient. K8s is Phase F.
- **âŒ Voice/camera/screen** â€” niche features, not our lane.
- **âŒ pgvector embeddings** â€” our keyword-scored SQLite recall works without an API call.
